# ğŸ“š BookGen-AI

> **AI-Powered SaaS Book Generation Platform**  
> Transform your ideas into professionally formatted books with the power of artificial intelligence.

## ğŸ‘¨â€ğŸ’» About the Developer

**Badr Ribzat** - Self-Taught Full-Stack Software Engineer from Morocco

ğŸ“§ **Contact**: [badrribzat@gmail.com](mailto:badrribzat@gmail.com)  
ğŸŒ **Portfolio**: [https://badr-portfolio.vercel.app](https://badr-portfolio.vercel.app)

### Professional Background
- **Self-taught Full-Stack Software Engineer** available for opportunities and collaborations
- **Experience across multiple domains**: Biomedical, Teaching IT, AI/Chatbot Development
- **Notable Projects**: 
  - Biomedical-AI Human Body Detection System
  - IT-Learning Platform
  - Internationalization Portfolio 
  - Resume Generator SaaS Platform
  - AI-Powered Chatbot Systems

ğŸ¤ **Available for**: Opportunities, collaborations, and technical discussions with companies across various industries

---

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/)
[![Django](https://img.shields.io/badge/Django-5.0+-green.svg)](https://www.djangoproject.com/)
[![Next.js](https://img.shields.io/badge/Next.js-14+-black.svg)](https://nextjs.org/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.0+-blue.svg)](https://www.typescriptlang.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.9+-red.svg)](https://pytorch.org/)
[![MongoDB](https://img.shields.io/badge/MongoDB-Atlas-green.svg)](https://www.mongodb.com/)

---

## ğŸŒŸ Features

### âœ… Current Implementation (Production Ready)

#### ğŸ” **Complete Authentication System**
- JWT-based authentication with refresh tokens
- Email verification and password reset workflows
- Secure user registration with validation
- Session management and logout functionality

#### ğŸ‘¤ **Advanced User Management**
- Extended user profiles with subscription tiers
- User analytics and activity tracking
- Profile customization and preferences
- Role-based access control

#### ğŸ“– **Intelligent Book Generation**
- Multi-step book creation wizard with progress tracking
- Real-time form validation with Zod schemas
- Genre-specific content templates
- Professional book metadata management

#### ğŸ¤– **Custom LLM Training Service**
- **Local JSON Storage Infrastructure** - Complete 12-domain data organization
- **Manual Data Collection Workflow** - Quality-controlled training data
- **Subscription-Tier Support** - Basic, Professional, Enterprise content generation
- **MongoDB Atlas Integration** - Production-ready database storage
- **GPT-2 Fine-tuning** - Domain-specific model customization
- **Data Validation Tools** - Comprehensive JSON validation and quality checks
- **Background Training Pipeline** - Async model training with progress tracking

#### ğŸ“„ **Professional PDF Generation**
- High-quality book formatting with ReportLab
- Custom templates and styling options
- Automated table of contents and indexing
- Professional typography and layout

#### ğŸ—ï¸ **Robust Infrastructure**
- Celery async task processing
- Redis message broker and caching
- Comprehensive error handling
- Production-ready logging and monitoring

### ğŸ”„ Coming Soon
- **Manual Data Collection** - Research and collect high-quality training data
- **Rich Book Editing** - Advanced text editor for content refinement
- **AI Cover Generation** - Automated professional book covers  
- **PDF Browser Preview** - In-browser PDF viewing and downloading
- **Payment Integration** - Subscription and billing management
- **Multi-language Support** - Internationalization features

---

## ğŸ—ï¸ System Architecture

```mermaid
graph TB
    subgraph "Frontend Layer"
        A[Next.js Frontend] --> B[TypeScript Components]
        B --> C[Tailwind CSS Styling]
        C --> D[Authentication Context]
    end
    
    subgraph "API Gateway"
        E[Django REST API] --> F[JWT Authentication]
        F --> G[User Management]
        G --> H[Book CRUD Operations]
    end
    
    subgraph "AI Processing Layer"
        I[FastAPI LLM Service] --> J[Local JSON Storage]
        J --> K[Data Validation Tool]
        K --> L[MongoDB Atlas Storage]
        L --> M[GPT-2 Fine-tuning]
        M --> N[Subscription-Tier Generation]
        N --> O[Domain-Specific Models]
    end
    
    subgraph "Data & Infrastructure"
        P[PostgreSQL] --> Q[User Data]
        R[MongoDB Atlas] --> S[Training Data]
        T[Redis] --> U[Caching & Tasks]
        V[Celery] --> W[Async Processing]
    end
    
    A --> E
    E --> I
    I --> R
    E --> P
    E --> T
    T --> V
```

---

## ğŸ“ Project Structure

```
bookgen-ai/
â”œâ”€â”€ ğŸ¨ frontend/                    # Next.js Application
â”‚   â”œâ”€â”€ app/                        # App Router pages
â”‚   â”‚   â”œâ”€â”€ auth/                   # Authentication flows
â”‚   â”‚   â”œâ”€â”€ dashboard/              # User dashboard
â”‚   â”‚   â””â”€â”€ api/                    # API routes
â”‚   â”œâ”€â”€ components/                 # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ auth/                   # Auth-specific components
â”‚   â”‚   â”œâ”€â”€ ui/                     # Base UI components
â”‚   â”‚   â””â”€â”€ layout/                 # Layout components
â”‚   â”œâ”€â”€ lib/                        # Utilities and configurations
â”‚   â”‚   â”œâ”€â”€ api/                    # API client functions
â”‚   â”‚   â”œâ”€â”€ contexts/               # React contexts
â”‚   â”‚   â”œâ”€â”€ hooks/                  # Custom React hooks
â”‚   â”‚   â””â”€â”€ validation/             # Zod schemas
â”‚   â””â”€â”€ shared/types/               # TypeScript type definitions
â”‚
â”œâ”€â”€ ğŸ”§ backend/                     # Django REST API
â”‚   â”œâ”€â”€ apps/                       # Django applications
â”‚   â”‚   â”œâ”€â”€ users/                  # User management
â”‚   â”‚   â”œâ”€â”€ core/                   # Core functionality
â”‚   â”‚   â””â”€â”€ books/                  # Book management
â”‚   â”œâ”€â”€ config/                     # Django configuration
â”‚   â”œâ”€â”€ tests/                      # Backend test suites
â”‚   â””â”€â”€ templates/                  # Email templates
â”‚
â”œâ”€â”€ ğŸ¤– llm-service/                 # FastAPI AI Service
â”‚   â”œâ”€â”€ app/                        # FastAPI application
â”‚   â”‚   â”œâ”€â”€ main.py                 # FastAPI app entry point
â”‚   â”‚   â”œâ”€â”€ ml/                     # Machine learning modules
â”‚   â”‚   â”‚   â”œâ”€â”€ data_schema.py      # MongoDB schemas
â”‚   â”‚   â”‚   â”œâ”€â”€ data_importer.py    # Local JSON import & validation
â”‚   â”‚   â”‚   â””â”€â”€ llm_trainer.py      # GPT-2 fine-tuning
â”‚   â”‚   â”œâ”€â”€ models/                 # Pydantic models
â”‚   â”‚   â””â”€â”€ api/                    # API route handlers
â”‚   â”œâ”€â”€ data/training_sets/         # Local JSON storage (12 domains)
â”‚   â”‚   â”œâ”€â”€ README.md               # Complete data collection guide
â”‚   â”‚   â”œâ”€â”€ template.json           # Universal data format template
â”‚   â”‚   â”œâ”€â”€ cybersecurity/          # Cybersecurity training data
â”‚   â”‚   â”‚   â””â”€â”€ template.json       # Domain-specific template
â”‚   â”‚   â”œâ”€â”€ ai_ml/                  # AI/ML training data
â”‚   â”‚   â”‚   â””â”€â”€ template.json       # Domain-specific template
â”‚   â”‚   â”œâ”€â”€ automation/             # Automation training data
â”‚   â”‚   â”œâ”€â”€ healthtech/             # HealthTech training data
â”‚   â”‚   â”œâ”€â”€ creator_economy/        # Creator Economy training data
â”‚   â”‚   â”œâ”€â”€ web3/                   # Web3 training data
â”‚   â”‚   â”œâ”€â”€ ecommerce/              # E-commerce training data
â”‚   â”‚   â”œâ”€â”€ data_analytics/         # Data Analytics training data
â”‚   â”‚   â”œâ”€â”€ gaming/                 # Gaming training data
â”‚   â”‚   â”œâ”€â”€ kids_parenting/         # Kids/Parenting training data
â”‚   â”‚   â”œâ”€â”€ nutrition/              # Nutrition training data
â”‚   â”‚   â””â”€â”€ recipes/                # Recipes training data
â”‚   â”œâ”€â”€ tests/                      # LLM service tests
â”‚   â”œâ”€â”€ demo_manual_import.py       # CLI import tool for local JSON
â”‚   â”œâ”€â”€ validate_data.py            # JSON validation and quality check tool
â”‚   â”œâ”€â”€ requirements.txt            # Python dependencies
â”‚   â”œâ”€â”€ README_CUSTOM_TRAINING.md   # Complete documentation
â”‚   â””â”€â”€ IMPLEMENTATION_COMPLETE.md  # Implementation summary
â”‚
â”œâ”€â”€ ğŸ“‹ shared/                      # Shared resources
â”‚   â””â”€â”€ types/                      # Common TypeScript types
â”‚
â”œâ”€â”€ ğŸ› ï¸ scripts/                     # Automation scripts
â”‚   â”œâ”€â”€ setup.sh                   # Development setup
â”‚   â”œâ”€â”€ run-tests.sh               # Test runner
â”‚   â””â”€â”€ seed-db.sh                 # Database seeding
â”‚
â”œâ”€â”€ ğŸ“‹ docs/                        # Documentation
â”‚   â”œâ”€â”€ LLM_SERVICE_COMPLETE.md    # LLM service documentation
â”‚   â””â”€â”€ IMPLEMENTATION_CHECKLIST.md # Implementation tracking
â”‚
â””â”€â”€ ğŸ³ docker-compose.yml           # Development environment
```

---

## ğŸš€ Quick Start

### Prerequisites
- **Docker & Docker Compose** (recommended for full setup)
- **Node.js 18+** and npm/yarn
- **Python 3.11+** with pip
- **Git** for version control

### ğŸ³ Automated Docker Setup (Recommended)
```bash
# Clone the repository
git clone https://github.com/BadrRibzat/bookgen-ai.git
cd bookgen-ai

# Make setup script executable and run
chmod +x scripts/setup.sh
./scripts/setup.sh

# Start all services
docker-compose up -d

# Verify services are running
docker-compose ps
```

### ğŸ”§ Manual Development Setup

#### 1. Backend (Django) Setup
```bash
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
python manage.py migrate
python manage.py createsuperuser
python manage.py runserver 8000
```

#### 2. Frontend (Next.js) Setup
```bash
cd frontend
npm install
npm run dev
```

#### 3. LLM Service (FastAPI) Setup
```bash
cd llm-service
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Verify local JSON storage infrastructure
ls data/training_sets/

# Start the service
uvicorn app.main:app --reload --host 0.0.0.0 --port 8002
```

### ï¿½ Service URLs
- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:8000
- **API Documentation**: http://localhost:8000/api/docs/
- **LLM Service**: http://localhost:8002
- **LLM API Docs**: http://localhost:8002/docs

---

## ğŸ§ª Testing & Quality Assurance

### Run All Tests
```bash
# Automated test runner
./scripts/run-tests.sh

# Individual service tests
cd backend && python manage.py test
cd frontend && npm test
cd llm-service && python test_setup.py
```

### Test Coverage
- **Backend**: Django TestCase, pytest, factory-boy
- **Frontend**: Jest, React Testing Library, Playwright E2E
- **LLM Service**: pytest-asyncio, FastAPI TestClient
- **Integration**: End-to-end workflow testing

---

## ğŸ¤– LLM Service Implementation

### Core Features
- **Local JSON Storage Infrastructure**: Complete 12-domain data organization with templates
- **Manual Data Collection**: Quality-controlled training data collection workflow
- **MongoDB Atlas Integration**: Production database for training data storage
- **GPT-2 Fine-tuning**: Lightweight, efficient model customization
- **Subscription-Tier Support**: Basic, Professional, Enterprise content generation
- **Data Validation Tools**: Comprehensive JSON validation and quality checking
- **Background Training Pipeline**: Async model training with progress tracking

### Data Collection Workflow
```bash
# 1. Read the comprehensive data collection guide
cat llm-service/data/training_sets/README.md

# 2. Validate your training data before importing
cd llm-service
python validate_data.py --all

# 3. Import validated training data
python demo_manual_import.py import-dir \
  --directory data/training_sets/cybersecurity \
  --domain-id cybersecurity

# 4. Train custom model
curl -X POST "http://localhost:8002/train" \
  -H "Content-Type: application/json" \
  -d '{"domain_id": "cybersecurity", "job_name": "Cybersecurity Model Training", "epochs": 3}'

# 5. Generate domain-specific content
curl -X POST "http://localhost:8002/generate" \
  -H "Content-Type: application/json" \
  -d '{"prompt": "What are the main cybersecurity threats in 2024?", "domain_id": "cybersecurity"}'
```

### Supported Domains & Templates
All 12 domains have dedicated folder structure with domain-specific JSON templates:

| Domain | Folder | Focus Areas |
|--------|--------|-------------|
| **Cybersecurity** | `cybersecurity/` | Vulnerabilities, threats, security practices |
| **AI & ML** | `ai_ml/` | Machine learning, AI research, implementations |
| **Automation** | `automation/` | RPA, workflow optimization, process improvement |
| **HealthTech** | `healthtech/` | Medical devices, digital health, telemedicine |
| **Creator Economy** | `creator_economy/` | Content monetization, platform strategies |
| **Web3** | `web3/` | Blockchain, cryptocurrency, DeFi, NFTs |
| **E-commerce** | `ecommerce/` | Online retail, marketplaces, conversion optimization |
| **Data Analytics** | `data_analytics/` | Business intelligence, data science, visualization |
| **Gaming** | `gaming/` | Game development, industry trends, monetization |
| **Kids/Parenting** | `kids_parenting/` | Child development, parenting advice, education |
| **Nutrition** | `nutrition/` | Dietary guidance, health optimization, supplements |
| **Recipes** | `recipes/` | Cooking techniques, recipe development, culinary arts |

### Local JSON Storage Format
```json
{
  "domain": "cybersecurity",
  "description": "Training data for cybersecurity domain",
  "version": "1.0.0",
  "total_examples": 100,
  "subscription_tiers": {
    "basic": {
      "system_prompt": "You are a cybersecurity assistant for beginners...",
      "max_complexity": 3,
      "target_audience": "beginners"
    },
    "professional": {
      "system_prompt": "You are a cybersecurity expert...",
      "max_complexity": 7,
      "target_audience": "professionals"  
    },
    "enterprise": {
      "system_prompt": "You are a senior cybersecurity consultant...",
      "max_complexity": 10,
      "target_audience": "enterprise_leaders"
    }
  },
  "training_examples": [
    {
      "id": "cyber_001",
      "input": "What is a SQL injection attack?",
      "output": "SQL injection is a code injection technique...",
      "difficulty_level": 3,
      "subscription_tier": "basic",
      "quality_score": 9.0
    }
  ]
}
```

### âœ… Implementation Example: Cybersecurity Domain

**Real-world data processing implementation with 5 authoritative sources:**

```bash
# Data Sources Integrated (Nov 2025):
# âœ“ NVD CVE Database (97 vulnerability examples)  
# âœ“ MITRE ATT&CK Framework (50 threat intelligence examples)
# âœ“ Ubuntu Security Notices (10 patch management examples)
# âœ“ ArXiv Cryptography Research (28 academic research examples)
# âœ“ Microsoft Security Updates (JSON format support)

# Processing Results:
# - 185 total training examples across all subscription tiers
# - Quality scores: 8.8-9.7/10 across all sources
# - Tier distribution: 5 basic, 125 professional, 55 enterprise

# Implementation Files:
llm-service/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_sources/cybersecurity/          # Original data files (gitignored)
â”‚   â”‚   â”œâ”€â”€ nvd_cve_2025.json              # NVD vulnerability data
â”‚   â”‚   â”œâ”€â”€ mitre_attack_enterprise.json    # MITRE ATT&CK techniques
â”‚   â”‚   â”œâ”€â”€ ubuntu_security_notices.xml     # Ubuntu security advisories  
â”‚   â”‚   â”œâ”€â”€ arxiv_crypto_papers.xml         # Academic research papers
â”‚   â”‚   â””â”€â”€ microsoft_security_updates.json # Microsoft security updates
â”‚   â””â”€â”€ training_sets/cybersecurity/        # Processed training data
â”‚       â”œâ”€â”€ vulnerabilities_cve_1.json      # 97 CVE examples
â”‚       â”œâ”€â”€ threat_intelligence_mitre_1.json # 50 MITRE examples
â”‚       â”œâ”€â”€ patch_management_ubuntu_1.json   # 10 Ubuntu examples
â”‚       â””â”€â”€ security_research_arxiv_1.json   # 28 research examples
â”œâ”€â”€ process_cyber_data_fixed.py             # Data processor script
â”œâ”€â”€ test_cybersecurity_data.py              # Quality validation
â””â”€â”€ Cyber-Security.sh                       # Integration automation

# Validation & Quality Check:
python3 test_cybersecurity_data.py
# âœ… 185 training examples ready
# âœ… All subscription tiers represented  
# âœ… High quality scores (8.8-9.7/10)
# âœ… Multiple authoritative data sources
```

**Key Implementation Features:**
- **Multi-format Processing**: Handles JSON (CVE, MITRE), XML (Ubuntu, ArXiv), RSS feeds
- **Intelligent Tier Assignment**: Automatic difficulty scoring based on CVSS, complexity
- **Quality Validation**: Comprehensive data structure and content validation
- **Production Ready**: Fully processed and validated for LLM training

---

## ğŸ” Environment Configuration

### Backend Environment (.env)
```bash
SECRET_KEY=your-secret-key
DEBUG=True
DATABASE_URL=postgresql://user:pass@localhost:5432/bookgen
REDIS_URL=redis://localhost:6379
EMAIL_HOST_USER=your-email@domain.com
EMAIL_HOST_PASSWORD=your-app-password
```

### LLM Service Environment (.env)
```bash
# MongoDB Atlas (shared with backend) - DO NOT commit real credentials
DATABASE_URL=mongodb+srv://<username>:<password>@<cluster>.mongodb.net/?retryWrites=true&w=majority&appName=<app-name>
MONGODB_DB_NAME=bookgen_ai

# Training Configuration
DEFAULT_BATCH_SIZE=4
DEFAULT_LEARNING_RATE=5e-5
DEFAULT_EPOCHS=3
MAX_SEQUENCE_LENGTH=512

# Hardware Settings
DEVICE=auto  # auto, cpu, cuda
USE_FP16=true

# Supported Domains
SUPPORTED_DOMAINS=cybersecurity,ai_ml,automation,healthtech,creator_economy,web3,ecommerce,data_analytics,gaming,kids_parenting,nutrition,recipes
```

### Frontend Environment (.env.local)
```bash
NEXT_PUBLIC_API_URL=http://localhost:8000
NEXT_PUBLIC_LLM_SERVICE_URL=http://localhost:8002
```

---

## ğŸ“Š Development Workflow

### Git Workflow
1. **Create Feature Branch**: `git checkout -b feature/your-feature-name`
2. **Implement Changes**: Follow coding standards and add tests
3. **Commit Changes**: Use conventional commits (feat:, fix:, docs:)
4. **Push & PR**: Open pull request with detailed description
5. **Code Review**: Address feedback and merge

### Code Quality Standards
- **Python**: Black formatting, isort imports, flake8 linting
- **TypeScript**: ESLint, Prettier, strict type checking
- **Testing**: Minimum 80% code coverage required
- **Documentation**: Inline comments and README updates

---

## ğŸ¤ Contributing

We welcome contributions! Please follow these guidelines:

1. **Fork** the repository and create your feature branch
2. **Follow** the existing code style and conventions
3. **Add tests** for new functionality
4. **Update documentation** as needed
5. **Submit** a pull request with a clear description

### Development Guidelines
- Use conventional commit messages
- Write comprehensive tests
- Update documentation for new features
- Follow existing architectural patterns
- Ensure all CI checks pass

---

## ğŸ“ˆ Roadmap

### Phase 3 (Next Phase - Manual Data Collection)
- [ ] Research and collect high-quality training data for target domains
- [ ] Validate and import training data using local JSON storage
- [ ] Train initial domain-specific models
- [ ] Test and refine content generation quality

### Phase 4 (Q1 2025)
- [ ] Rich text editor integration
- [ ] AI-powered cover generation
- [ ] Advanced PDF customization
- [ ] Multi-language support

### Phase 5 (Future)
- [ ] Payment and subscription system
- [ ] Collaboration features
- [ ] Mobile application
- [ ] Enterprise features

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **OpenAI** for transformer architecture inspiration
- **Hugging Face** for the transformers library
- **MongoDB** for Atlas database services
- **Vercel** for Next.js framework
- **Django Software Foundation** for the web framework

---

**Made with â¤ï¸ by the BookGen-AI Team**

*Last updated: November 4, 2025*
 # ï¿½ BookGen-AI

 ![BookGen-AI logo](frontend/public/favicon.svg)

 > **AI-Powered SaaS Book Generation Platform**
 > Transform your ideas into professionally formatted books with the power of artificial intelligence.

 [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
 [![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/)
 [![Django](https://img.shields.io/badge/Django-5.0+-green.svg)](https://www.djangoproject.com/)
 [![Next.js](https://img.shields.io/badge/Next.js-14+-black.svg)](https://nextjs.org/)
 [![TypeScript](https://img.shields.io/badge/TypeScript-5.0+-blue.svg)](https://www.typescriptlang.org/)

 ---

 ## ğŸŒŸ Features

 ### Current Implementation (Phase 1 & 2)
 - âœ… Secure Authentication (JWT + email verification)
 - âœ… User Profiles with analytics
 - âœ… Multi-step Book Generation wizard
 - âœ… FastAPI LLM service (extensible mock implementation)
 - âœ… Production-ready PDF generation pipeline

 ### Coming Soon
 - ğŸ”„ Rich book editing UI
 - ğŸ¤– Custom LLM fine-tuning
 - ğŸ¨ AI cover design
 - ğŸ“„ In-browser PDF preview
 - ğŸ’³ Payment/subscription integration

 ---

 ## ğŸ—ï¸ Technical Architecture

 This repository is a monorepo with three main components:

 - Backend: Django + DRF, Celery, MongoDB
 - Frontend: Next.js (App Router) + TypeScript + Tailwind
 - LLM Service: FastAPI (mock LLM for content generation)

 Other infra: Redis (broker), Cloudinary (assets), Docker Compose for local development.

 ---

 ## ğŸ“ Project Structure (high-level)

 The project tree below is a concise overview for quick orientation â€” browse the repo for full details.

 ```
 bookgen-ai/
 â”œâ”€â”€ backend/                    # Django REST API
 â”œâ”€â”€ frontend/                   # Next.js application
 â”œâ”€â”€ llm-service/                # FastAPI AI service
 â”œâ”€â”€ shared/                     # Shared TypeScript types
 â”œâ”€â”€ scripts/                    # Automation scripts (setup, seeds, tests)
 â””â”€â”€ docker-compose.yml          # Development compose file
 ```

 ---

 ## ğŸš€ Quick Start

 Follow these steps for a fast local development setup (Docker recommended):

 ### Prerequisites
 - Docker & Docker Compose
 - Node 18+ and npm
 - Python 3.11+
 - Git

 ### Automated setup
 ```bash
 git clone https://github.com/yourusername/bookgen-ai.git
 cd bookgen-ai
 chmod +x scripts/setup.sh
 ./scripts/setup.sh
 docker-compose up -d
 ```

 Access:
 - Frontend: http://localhost:3000
 - Backend: http://localhost:8000
 - API docs: http://localhost:8000/api/docs/

 If you prefer manual setup, the original manual steps are preserved in the repository and the `scripts/` folder.

 ---

 ## ğŸ§ª Testing

 Run all tests locally:
 ```bash
 ./scripts/run-tests.sh
 ```

 Backend unit tests (pytest) and frontend tests (Jest/Playwright) are available.

 ---

 ## ğŸ“Š Development Workflow

 1. Create a feature branch: `git checkout -b feature/your-feature`
 2. Implement & test
 3. Commit with Conventional Commits
 4. Push and open PR

 ---

 ## ğŸ” Environment

 Use `.env.example` files as templates; do not commit secrets. Key env variables are documented in the backend and frontend directories.

 ---

 ## ğŸ¤ Contributing

 We welcome contributions. Please follow the projectâ€™s branching and commit conventions. See the CONTRIBUTING.md (if added) for details.

 ---

 ## ğŸ“ License

 MIT â€” see the `LICENSE` file.

 ---

 **Made with â¤ by the BookGen-AI Team**
